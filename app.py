# =============================
# âœ… ì„œë¹„ìŠ¤êµ¬ë¶„ ì»¬ëŸ¼ ìƒì„±
# =============================
classification_rules = {
    'í†µì‹ ': 'ì „ìš©íšŒì„ ', 'íšŒì„ ': 'ì „ìš©íšŒì„ ', 'ì „ì†¡': 'ì „ìš©íšŒì„ ', 'ë§': 'ì „ìš©íšŒì„ ',
    'ì¸í„°ë„·': 'ì¸í„°ë„·', 'ì½œ': 'ì „í™”', 'ë¬¸ì': 'SMS', 'ê³ ê°ì„¼í„°': 'ì „í™”',
    'Cê·¸ë£¹': 'ì „í™”', 'ì „ìš©íšŒì„ ': 'ì „ìš©íšŒì„ ', 'ë‹¨ë§ê¸°': 'NSI',
    'ìŠ¤ë§ˆíŠ¸ê¸°ê¸°': 'NSI', 'ìŠ¤ë§ˆíŠ¸ ê¸°ê¸°': 'NSI', 'LTE': 'ë¬´ì„ ', '5G': 'ë¬´ì„ ', 'ë¬´ì„ ': 'ë¬´ì„ ',
    'ëŒ€í‘œë²ˆí˜¸': 'ì „í™”', 'IDC': 'IDC', 'CDN': 'IDC', 'ìŠ¤ì¿¨ë„·': 'ì „ìš©íšŒì„ ',
    'í´ë¼ìš°ë“œ': 'IDC', 'ì™€ì´íŒŒì´': 'ì¸í„°ë„·', 'ë°±ì—…': 'IDC', 'IoT': 'ë¬´ì„ ',
    'ë©”ì‹œì§€': 'ë¬¸ì', 'ë©”ì„¸ì§€': 'ë¬¸ì', 'Contact': 'ì „í™”', 'cloud': 'IDC',
    'ë””ë„ìŠ¤': 'ë³´ì•ˆ', 'ë³´ì•ˆ': 'ë³´ì•ˆ', 'ê´€ì œ': 'ë³´ì•ˆ', 'ì¬ë‚œ': 'ë³´ì•ˆ',
    'ìœ ì§€ë³´ìˆ˜': 'ìœ ì§€ë³´ìˆ˜',
    'ì•ˆì‹¬ì•Œë¦¬ë¯¸': 'NSI',
    'ì•ˆì‹¬ ì•Œë¦¬ë¯¸': 'NSI',
    'ì „ê¸°ê³µì‚¬': 'ìœ ì§€ë³´ìˆ˜',
    'ìŠ¤í† ë¦¬ì§€': 'NSI',
    'ìŒì‹ë¬¼': 'NSI',
    'ì†Œì•¡': 'NSI',
    'í†µí™”': 'ì „í™”',
    'ìœ„í˜‘': 'ì „í™”',
    'ì „í™”ê¸°': 'ì „í™”',
    'ëª¨ë°”ì¼í–‰ì •ì „í™”': 'ì „í™”',
    'íœ´ëŒ€í°': 'ë¬´ì„ ',
    'LED': 'NSI',
    'ì¡°ëª…': 'NSI',
    'íƒœë¸”ë¦¿': 'NSI',
    'ë„¤íŠ¸ì›Œí¬': 'ì „ìš©íšŒì„ ',
    'ìŠ¤ë§ˆíŠ¸ë‹¨ë§': 'NSI',
    'ìš´ì˜ëŒ€í–‰': 'ìœ ì§€ë³´ìˆ˜',
    'ëª¨ë°”ì¼': 'ë¬´ì„ ',
    'AI': 'AI',
    'ì¸ê³µì§€ëŠ¥': 'AI',
    'ë¹…ë°ì´í„°': 'AI',
    'êµ¬ë‚´ì „í™”': 'ì „í™”', 'IPTV': 'ë¯¸ë””ì–´', 'CCTV': 'CCTV'
}


def add_service_category(df: pd.DataFrame) -> pd.DataFrame:
    if "ì„œë¹„ìŠ¤êµ¬ë¶„" in df.columns:
        df = df.copy()
        _ = df.pop("ì„œë¹„ìŠ¤êµ¬ë¶„")

    df["ì„œë¹„ìŠ¤êµ¬ë¶„"] = "ë¯¸ë¶„ë¥˜"  # ë§¨ ë’¤ì— ìƒì„±

    if "ì…ì°°ê³µê³ ëª…" not in df.columns:
        return df

    rule_items = sorted(classification_rules.items(), key=lambda x: len(x[0]), reverse=True)

    def classify_title(title: str) -> str:
        t = "" if pd.isna(title) else str(title)
        tl = t.lower()
        for k, label in rule_items:
            if (k in t) or (k.lower() in tl):
                return label
        return "ë¯¸ë¶„ë¥˜"

    df["ì„œë¹„ìŠ¤êµ¬ë¶„"] = df["ì…ì°°ê³µê³ ëª…"].apply(classify_title)
    return df


# =============================
# ì²¨ë¶€ ë§í¬ ë§¤íŠ¸ë¦­ìŠ¤
# =============================
CSS_COMPACT = """
<style>
.attch-wrap { display:flex; flex-direction:column; gap:14px; background:#eef6ff; padding:8px; border-radius:12px; }
.attch-card { border:1px solid #cfe1ff; border-radius:12px; padding:12px 14px; background:#f4f9ff; }
.attch-title { font-weight:700; margin-bottom:8px; font-size:13px; line-height:1.4; word-break:break-word; color:#0b2e5b; }
.attch-grid { display:grid; grid-template-columns:repeat(auto-fit, minmax(220px, 1fr)); gap:10px; }
.attch-box { border:1px solid #cfe1ff; border-radius:10px; overflow:hidden; background:#ffffff; }
.attch-box-header { background:#0d6efd; color:#fff; font-weight:700; font-size:11px; padding:6px 8px; display:flex; align-items:center; justify-content:space-between; }
.badge { background:rgba(255,255,255,0.2); color:#fff; padding:0 6px; border-radius:999px; font-size:10px; }
.attch-box-body { padding:8px; font-size:12px; line-height:1.45; word-break:break-word; color:#0b2447; }
.attch-box-body a { color:#0b5ed7; text-decoration:none; }
.attch-box-body a:hover { text-decoration:underline; }
.attch-box-body details summary { cursor:pointer; font-weight:600; list-style:none; outline:none; color:#0b2447; }
.attch-box-body details summary::-webkit-details-marker { display:none; }
.attch-box-body details summary:after { content:"â–¼"; font-size:10px; margin-left:6px; color:#0b2447; }
</style>
"""


def _is_url(val: str) -> bool:
    s = str(val).strip()
    return s.startswith("http://") or s.startswith("https://")


def _filename_from_url(url: str) -> str:
    try:
        path = urlparse(url).path
        if not path:
            return url
        return unquote(path.split("/")[-1]) or url
    except Exception:
        return url


def build_attachment_matrix(df_like: pd.DataFrame, title_col: str) -> pd.DataFrame:
    if title_col not in df_like.columns:
        return pd.DataFrame(columns=[title_col, "ë³¸ê³µê³ ë§í¬", "ì œì•ˆìš”ì²­ì„œ", "ê³µê³ ì„œ", "ê³¼ì—…ì§€ì‹œì„œ", "ê·œê²©ì„œ", "ê¸°íƒ€"])
    buckets = {}

    def add_link(title, category, name, url):
        if title not in buckets:
            buckets[title] = {k: {} for k in ["ë³¸ê³µê³ ë§í¬", "ì œì•ˆìš”ì²­ì„œ", "ê³µê³ ì„œ", "ê³¼ì—…ì§€ì‹œì„œ", "ê·œê²©ì„œ", "ê¸°íƒ€"]}
        if url not in buckets[title][category]:
            buckets[title][category][url] = name

    n_cols = df_like.shape[1]
    for _, row in df_like.iterrows():
        title = str(row.get(title_col, ""))
        if not title:
            continue
        for j in range(1, n_cols):
            url_col = df_like.columns[j]
            name_col = df_like.columns[j - 1]
            url_val = row.get(url_col, None)
            name_val = row.get(name_col, None)
            if pd.isna(url_val):
                continue
            raw = str(url_val).strip()
            if _is_url(raw):
                urls = [raw]
            else:
                toks = [u.strip() for u in raw.replace("\n", ";").split(";")]
                urls = [u for u in toks if _is_url(u)]
                if not urls:
                    continue
            name_base = "" if pd.isna(name_val) else str(name_val).strip()
            name_tokens = [n.strip() for n in (name_base.replace("\n", ";") if name_base else "").split(";")]
            for k, u in enumerate(urls):
                disp_name = name_tokens[k] if k < len(name_tokens) and name_tokens[k] else (name_base or _filename_from_url(u))
                low = (disp_name or "").lower() + " " + _filename_from_url(u).lower()

                if ("ì œì•ˆìš”ì²­ì„œ" in low) or ("rfp" in low):
                    add_link(title, "ì œì•ˆìš”ì²­ì„œ", disp_name, u)
                elif ("ê³µê³ ì„œ" in low) or ("ê³µê³ ë¬¸" in low):
                    add_link(title, "ê³µê³ ì„œ", disp_name, u)
                elif "ê³¼ì—…ì§€ì‹œì„œ" in low:
                    add_link(title, "ê³¼ì—…ì§€ì‹œì„œ", disp_name, u)
                elif ("ê·œê²©ì„œ" in low) or ("spec" in low):
                    add_link(title, "ê·œê²©ì„œ", disp_name, u)
                else:
                    add_link(title, "ê¸°íƒ€", disp_name, u)

    def join_html(d):
        if not d:
            return ""
        return " | ".join([f"<a href='{url}' target='_blank' rel='nofollow noopener'>{name}</a>" for url, name in d.items()])

    rows = []
    for title, catmap in buckets.items():
        rows.append(
            {
                title_col: title,
                "ë³¸ê³µê³ ë§í¬": join_html(catmap["ë³¸ê³µê³ ë§í¬"]),
                "ì œì•ˆìš”ì²­ì„œ": join_html(catmap["ì œì•ˆìš”ì²­ì„œ"]),
                "ê³µê³ ì„œ": join_html(catmap["ê³µê³ ì„œ"]),
                "ê³¼ì—…ì§€ì‹œì„œ": join_html(catmap["ê³¼ì—…ì§€ì‹œì„œ"]),
                "ê·œê²©ì„œ": join_html(catmap["ê·œê²©ì„œ"]),
                "ê¸°íƒ€": join_html(catmap["ê¸°íƒ€"]),
            }
        )
    return pd.DataFrame(rows).sort_values(by=[title_col]).reset_index(drop=True)


def render_attachment_cards_html(df_links: pd.DataFrame, title_col: str) -> str:
    cat_cols = ["ë³¸ê³µê³ ë§í¬", "ì œì•ˆìš”ì²­ì„œ", "ê³µê³ ì„œ", "ê³¼ì—…ì§€ì‹œì„œ", "ê·œê²©ì„œ", "ê¸°íƒ€"]
    present_cols = [c for c in cat_cols if c in df_links.columns]
    if title_col not in df_links.columns:
        return "<p>í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"
    html = [CSS_COMPACT, '<div class="attch-wrap">']
    for _, r in df_links.iterrows():
        title = str(r.get(title_col, "") or "")
        html.append('<div class="attch-card">')
        html.append(f'<div class="attch-title">{title}</div>')
        html.append('<div class="attch-grid">')
        for col in present_cols:
            raw = str(r.get(col, "") or "").strip()
            if not raw:
                continue
            parts = [p.strip() for p in raw.split("|") if p.strip()]
            count = len(parts)
            if count <= 3:
                body_html = raw
            else:
                head = " | ".join(parts[:3])
                tail = " | ".join(parts[3:])
                body_html = head + f'<details style="margin-top:6px;"><summary>ë”ë³´ê¸° ({count-3})</summary>{tail}</details>'
            html.append('<div class="attch-box">')
            html.append(f'<div class="attch-box-header">{col} <span class="badge">{count}</span></div>')
            html.append(f'<div class="attch-box-body">{body_html}</div>')
            html.append('</div>')
        html.append('</div></div>')
    html.append('</div>')
    return "\n".join(html)


# =============================
# ë²¤ë” ì •ê·œí™”/ìƒ‰ìƒ
# =============================
VENDOR_COLOR_MAP = {
    "ì—˜ì§€ìœ í”ŒëŸ¬ìŠ¤": "#FF1493",
    "ì¼€ì´í‹°": "#FF0000",
    "ì—ìŠ¤ì¼€ì´ë¸Œë¡œë“œë°´ë“œ": "#FFD700",
    "ì—ìŠ¤ì¼€ì´í…”ë ˆì½¤": "#1E90FF",
}
OTHER_SEQ = ["#2E8B57", "#6B8E23", "#556B2F", "#8B4513", "#A0522D", "#CD853F", "#228B22", "#006400"]


def normalize_vendor(name: str) -> str:
    s = str(name) if pd.notna(name) else ""
    if "ì—˜ì§€ìœ í”ŒëŸ¬ìŠ¤" in s or "LGìœ í”ŒëŸ¬ìŠ¤" in s or "LG U" in s.upper():
        return "ì—˜ì§€ìœ í”ŒëŸ¬ìŠ¤"
    if s.startswith("ì¼€ì´í‹°") or " KT" in s or s == "KT" or "ì£¼ì‹íšŒì‚¬ ì¼€ì´í‹°" in s:
        return "ì¼€ì´í‹°"
    if "ë¸Œë¡œë“œë°´ë“œ" in s or "SKë¸Œë¡œë“œë°´ë“œ" in s:
        return "ì—ìŠ¤ì¼€ì´ë¸Œë¡œë“œë°´ë“œ"
    if "í…”ë ˆì½¤" in s or "SKí…”ë ˆì½¤" in s:
        return "ì—ìŠ¤ì¼€ì´í…”ë ˆì½¤"
    return s or "ê¸°íƒ€"


# =============================
# ë¡œê·¸ì¸ ê²Œì´íŠ¸ & ì‚¬ì´ë“œë°”
# =============================
INFO_BOX = "ì‚¬ë²ˆ/ìƒë…„ì›”ì¼ì€ ì‚¬ë‚´ ë°°í¬ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤."


def login_gate():
    st.title("ğŸ” ë¡œê·¸ì¸")
    emp = st.text_input("ì‚¬ë²ˆ", value="", placeholder="ì˜ˆ: 9999")
    dob = st.text_input("ìƒë…„ì›”ì¼(YYMMDD)", value="", placeholder="ì˜ˆ: 990101", type="password")
    users = _get_auth_users_from_secrets()
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ë¡œê·¸ì¸", type="primary", use_container_width=True):
            ok = False
            if emp == "2855" and dob == "910518":
                ok = True
                st.session_state["role"] = "admin"
            elif any((str(u.get("emp")) == emp and str(u.get("dob")) == dob) for u in users):
                ok = True
                st.session_state["role"] = "user"
            if ok:
                st.session_state["authed"] = True
                st.success("ë¡œê·¸ì¸ ì„±ê³µ")
                st.rerun()
            else:
                st.error("ì¸ì¦ ì‹¤íŒ¨. ì‚¬ë²ˆ/ìƒë…„ì›”ì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    with col2:
        st.info(INFO_BOX)


def render_sidebar_base():
    st.sidebar.title("ğŸ“‚ ë°ì´í„° ì—…ë¡œë“œ")

    up = st.sidebar.file_uploader(
        "filtered ì‹œíŠ¸ê°€ í¬í•¨ëœ ë³‘í•© ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)",
        type=["xlsx"],
        key="uploaded_file"
    )
    if up is not None:
        st.session_state["uploaded_file_obj"] = up

    st.sidebar.radio("# ğŸ“‹ ë©”ë‰´ ì„ íƒ", ["ì¡°ë‹¬ì…ì°°ê²°ê³¼í˜„í™©", "ë‚´ê³ ê° ë¶„ì„í•˜ê¸°"], key="menu")

    with st.sidebar.expander("ğŸ”‘ Gemini API Key", expanded=True):
        if _get_gemini_key_from_secrets():
            st.success("st.secretsì—ì„œ Gemini í‚¤ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ê¶Œì¥)")
        key_in = st.text_input(
            "ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ ì…ë ¥(ì„ íƒ) â€” st.secretsê°€ ìš°ì„  ì ìš©ë©ë‹ˆë‹¤.",
            type="password",
            placeholder="AIza...."
        )
        if st.button("í‚¤ ì ìš©", use_container_width=True):
            if key_in and key_in.strip().startswith("AIza"):
                st.session_state["GEMINI_API_KEY"] = key_in.strip()
                st.success("ì„¸ì…˜ì— Gemini í‚¤ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ìœ íš¨í•œ Gemini í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (AIza...).")

    if _get_gemini_key():
        st.sidebar.success("Gemini ì‚¬ìš© ê°€ëŠ¥")
    else:
        st.sidebar.warning("Gemini ë¹„í™œì„± â€” st.secrets.GEMINI_API_KEY ì„¤ì • í•„ìš”")

    if _cloudconvert_supported():
        st.sidebar.success("CloudConvert ì‚¬ìš© ê°€ëŠ¥")
    else:
        st.sidebar.warning("CloudConvert ë¹„í™œì„± â€” st.secrets.CLOUDCONVERT_API_KEY ì„¤ì • í•„ìš”")
    
    # [ì‚­ì œë¨] Gemini ì¶”ê°€ ìš”êµ¬ì‚¬í•­ ì…ë ¥ì°½ ì œê±°


def render_sidebar_filters(df: pd.DataFrame):
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ§° í•„í„°")

    if "ì„œë¹„ìŠ¤êµ¬ë¶„" in df.columns:
        options = sorted([str(x) for x in df["ì„œë¹„ìŠ¤êµ¬ë¶„"].dropna().unique()])
        defaults = [x for x in SERVICE_DEFAULT if x in options]
        st.sidebar.multiselect(
            "ì„œë¹„ìŠ¤êµ¬ë¶„ ì„ íƒ",
            options=options,
            default=defaults,
            key="svc_filter_ms",
        )

    st.sidebar.subheader("ğŸ” ë¶€ê°€ í•„í„°")
    st.sidebar.checkbox("(í•„í„°)ë‚™ì°°ìì„ ì •ì—¬ë¶€ = 'Y' ë§Œ ë³´ê¸°", value=True, key="only_winner")

    if "ëŒ€í‘œì—…ì²´" in df.columns:
        company_list = sorted(df["ëŒ€í‘œì—…ì²´"].dropna().unique())
        st.sidebar.multiselect("ëŒ€í‘œì—…ì²´ í•„í„° (ë³µìˆ˜ ê°€ëŠ¥)", company_list, key="selected_companies")

    demand_col_sidebar = "ìˆ˜ìš”ê¸°ê´€ëª…" if "ìˆ˜ìš”ê¸°ê´€ëª…" in df.columns else ("ìˆ˜ìš”ê¸°ê´€" if "ìˆ˜ìš”ê¸°ê´€" in df.columns else None)
    if demand_col_sidebar:
        org_list = sorted(df[demand_col_sidebar].dropna().unique())
        st.sidebar.multiselect(f"{demand_col_sidebar} í•„í„° (ë³µìˆ˜ ê°€ëŠ¥)", org_list, key="selected_orgs")

    st.sidebar.subheader("ğŸ“† ê³µê³ ê²Œì‹œì¼ì í•„í„°")
    if "ê³µê³ ê²Œì‹œì¼ì_date" in df.columns:
        df["_tmp_date"] = pd.to_datetime(df["ê³µê³ ê²Œì‹œì¼ì_date"], errors="coerce")
    else:
        df["_tmp_date"] = pd.NaT

    df["_tmp_year"] = df["_tmp_date"].dt.year
    year_list = sorted([int(x) for x in df["_tmp_year"].dropna().unique()])
    st.sidebar.multiselect("ì—°ë„ ì„ íƒ (ë³µìˆ˜ ê°€ëŠ¥)", year_list, default=[], key="selected_years")

    df["_tmp_month"] = df["_tmp_date"].dt.month
    st.sidebar.multiselect("ì›” ì„ íƒ (ë³µìˆ˜ ê°€ëŠ¥)", list(range(1, 13)), default=[], key="selected_months")


# ===== ì§„ì… ê°€ë“œ =====
if not st.session_state.get("authed", False):
    login_gate()
    st.stop()

render_sidebar_base()

# =============================
# ì—…ë¡œë“œ/ë°ì´í„° ë¡œë“œ
# =============================
uploaded_file = st.session_state.get("uploaded_file_obj")
if not uploaded_file:
    st.title("ğŸ“Š ì¡°ë‹¬ì…ì°° ë¶„ì„ ì‹œìŠ¤í…œ")
    st.caption("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ 'filtered' ì‹œíŠ¸ë¥¼ í¬í•¨í•œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

try:
    df = pd.read_excel(uploaded_file, sheet_name="filtered", engine="openpyxl")
except Exception as e:
    st.error(f"ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

df = add_service_category(df)
df_original = df.copy()

render_sidebar_filters(df_original)

# =============================
# ì‚¬ì´ë“œë°” í•„í„° ê°’ ì½ê¸° & ì ìš©
# =============================
service_selected = st.session_state.get("svc_filter_ms", [])
only_winner = st.session_state.get("only_winner", True)
selected_companies = st.session_state.get("selected_companies", [])
selected_orgs = st.session_state.get("selected_orgs", [])
selected_years = st.session_state.get("selected_years", [])
selected_months = st.session_state.get("selected_months", [])

demand_col_sidebar = "ìˆ˜ìš”ê¸°ê´€ëª…" if "ìˆ˜ìš”ê¸°ê´€ëª…" in df.columns else ("ìˆ˜ìš”ê¸°ê´€" if "ìˆ˜ìš”ê¸°ê´€" in df.columns else None)

df_filtered = df.copy()
if "ê³µê³ ê²Œì‹œì¼ì_date" in df_filtered.columns:
    df_filtered["ê³µê³ ê²Œì‹œì¼ì_date"] = pd.to_datetime(df_filtered["ê³µê³ ê²Œì‹œì¼ì_date"], errors="coerce")
else:
    df_filtered["ê³µê³ ê²Œì‹œì¼ì_date"] = pd.NaT

df_filtered["year"] = df_filtered["ê³µê³ ê²Œì‹œì¼ì_date"].dt.year
df_filtered["month"] = df_filtered["ê³µê³ ê²Œì‹œì¼ì_date"].dt.month

if selected_years:
    df_filtered = df_filtered[df_filtered["year"].isin(selected_years)]
if selected_months:
    df_filtered = df_filtered[df_filtered["month"].isin(selected_months)]
if only_winner and "ë‚™ì°°ìì„ ì •ì—¬ë¶€" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["ë‚™ì°°ìì„ ì •ì—¬ë¶€"] == "Y"]
if selected_companies and "ëŒ€í‘œì—…ì²´" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["ëŒ€í‘œì—…ì²´"].isin(selected_companies)]
if selected_orgs and demand_col_sidebar:
    df_filtered = df_filtered[df_filtered[demand_col_sidebar].isin(selected_orgs)]
if service_selected and "ì„œë¹„ìŠ¤êµ¬ë¶„" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["ì„œë¹„ìŠ¤êµ¬ë¶„"].astype(str).isin(service_selected)]


# =============================
# ê¸°ë³¸ ë¶„ì„(ì°¨íŠ¸)
# =============================
def render_basic_analysis_charts(base_df: pd.DataFrame):
    def pick_unit(max_val: float):
        if max_val >= 1_0000_0000_0000:
            return ("ì¡°ì›", 1_0000_0000_0000)
        elif max_val >= 100_000_000:
            return ("ì–µì›", 100_000_000)
        elif max_val >= 1_000_000:
            return ("ë°±ë§Œì›", 1_000_000)
        else:
            return ("ì›", 1)

    def apply_unit(values: pd.Series, mode: str = "ìë™"):
        unit_map = {"ì›": ("ì›", 1), "ë°±ë§Œì›": ("ë°±ë§Œì›", 1_000_000), "ì–µì›": ("ì–µì›", 100_000_000), "ì¡°ì›": ("ì¡°ì›", 1_0000_0000_0000)}
        if mode == "ìë™":
            u, f = pick_unit(values.max() if len(values) else 0)
            return values / f, u
        else:
            u, f = unit_map.get(mode, ("ì›", 1))
            return values / f, u

    st.markdown("## ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„")
    st.caption("â€» ì´í•˜ ëª¨ë“  ì°¨íŠ¸ëŠ” **ë‚™ì°°ìì„ ì •ì—¬ë¶€ == 'Y'** ê¸°ì¤€ì…ë‹ˆë‹¤.")

    if "ë‚™ì°°ìì„ ì •ì—¬ë¶€" not in base_df.columns:
        st.warning("ì»¬ëŸ¼ 'ë‚™ì°°ìì„ ì •ì—¬ë¶€'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    dwin = base_df[base_df["ë‚™ì°°ìì„ ì •ì—¬ë¶€"] == "Y"].copy()
    if dwin.empty:
        st.warning("ë‚™ì°°(Y) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for col in ["íˆ¬ì°°ê¸ˆì•¡", "ë°°ì •ì˜ˆì‚°ê¸ˆì•¡", "íˆ¬ì°°ìœ¨"]:
        if col in dwin.columns:
            dwin[col] = pd.to_numeric(dwin[col], errors="coerce")

    if "ëŒ€í‘œì—…ì²´" in dwin.columns:
        dwin["ëŒ€í‘œì—…ì²´_í‘œì‹œ"] = dwin["ëŒ€í‘œì—…ì²´"].map(normalize_vendor)
    else:
        dwin["ëŒ€í‘œì—…ì²´_í‘œì‹œ"] = "ê¸°íƒ€"

    st.markdown("### 1) ëŒ€í‘œì—…ì²´ë³„ ë¶„í¬")
    unit_choice = st.selectbox("íŒŒì´ì°¨íŠ¸(íˆ¬ì°°ê¸ˆì•¡ í•©ê³„) í‘œê¸° ë‹¨ìœ„", ["ìë™", "ì›", "ë°±ë§Œì›", "ì–µì›", "ì¡°ì›"], index=0)
    col_pie1, col_pie2 = st.columns(2)

    with col_pie1:
        if "íˆ¬ì°°ê¸ˆì•¡" in dwin.columns:
            sum_by_company = dwin.groupby("ëŒ€í‘œì—…ì²´_í‘œì‹œ")["íˆ¬ì°°ê¸ˆì•¡"].sum().reset_index().sort_values("íˆ¬ì°°ê¸ˆì•¡", ascending=False)
            scaled_vals, unit_label = apply_unit(sum_by_company["íˆ¬ì°°ê¸ˆì•¡"].fillna(0), unit_choice)
            sum_by_company["í‘œì‹œê¸ˆì•¡"] = scaled_vals
            fig1 = px.pie(
                sum_by_company,
                names="ëŒ€í‘œì—…ì²´_í‘œì‹œ",
                values="í‘œì‹œê¸ˆì•¡",
                title=f"ëŒ€í‘œì—…ì²´ë³„ íˆ¬ì°°ê¸ˆì•¡ í•©ê³„ â€” ë‹¨ìœ„: {unit_label}",
                color="ëŒ€í‘œì—…ì²´_í‘œì‹œ",
                color_discrete_map=VENDOR_COLOR_MAP,
                color_discrete_sequence=OTHER_SEQ,
            )
            st.plotly_chart(fig1, use_container_width=True)

    with col_pie2:
        cnt_by_company = dwin["ëŒ€í‘œì—…ì²´_í‘œì‹œ"].value_counts().reset_index()
        cnt_by_company.columns = ["ëŒ€í‘œì—…ì²´_í‘œì‹œ", "ê±´ìˆ˜"]
        fig2 = px.pie(
            cnt_by_company,
            names="ëŒ€í‘œì—…ì²´_í‘œì‹œ",
            values="ê±´ìˆ˜",
            title="ëŒ€í‘œì—…ì²´ë³„ ë‚™ì°° ê±´ìˆ˜",
            color="ëŒ€í‘œì—…ì²´_í‘œì‹œ",
            color_discrete_map=VENDOR_COLOR_MAP,
            color_discrete_sequence=OTHER_SEQ,
        )
        st.plotly_chart(fig2, use_container_width=True)


# =============================
# LLM ë¶„ì„ìš© í…ìŠ¤íŠ¸ ì¶”ì¶œ (Smart Fallback ì ìš©)
# =============================
TEXT_EXTS = {".txt", ".csv", ".md", ".log"}
DIRECT_PDF_EXTS = {".pdf"}
BINARY_EXTS = {".hwp", ".hwpx", ".doc", ".docx", ".ppt", ".pptx", ".xls", ".xlsx"}


def extract_text_combo_gemini_first(uploaded_files):
    combined_texts, convert_logs, generated_pdfs = [], [], []

    for idx, f in enumerate(uploaded_files):
        name = f.name
        data = f.read()
        ext = (os.path.splitext(name)[1] or "").lower()

        # ë¬´ë£Œ í‹°ì–´ 429 ë°©ì§€ìš© ì§€ì—°
        if idx > 0:
            time.sleep(2.0)
        
        # âœ… ë°˜í™˜ê°’ 2ê°œ(í…ìŠ¤íŠ¸, ëª¨ë¸) ë°›ê¸°
        gem_txt, used_model = gemini_try_extract_text_from_file(data, name)
        
        if gem_txt:
            convert_logs.append(f"ğŸ¤– {name}: Gemini[{used_model}] ì¶”ì¶œ ì„±ê³µ ({len(gem_txt)}ì)")
            combined_texts.append(f"\n\n===== [{name} | Gemini-{used_model}] =====\n{gem_txt}\n")
            continue
        else:
            convert_logs.append(f"ğŸ¤– {name}: Gemini ì¶”ì¶œ ì‹¤íŒ¨ â†’ í´ë°± ì§„í–‰")

        if ext in {".hwp", ".hwpx"}:
            try:
                txt, fmt = convert_to_text(data, name)
                convert_logs.append(f"ğŸ“„ {name}: ë¡œì»¬ {fmt} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ ({len(txt)} chars)")
                combined_texts.append(f"\n\n===== [{name} | ë¡œì»¬ {fmt} ì¶”ì¶œ] =====\n{_redact_secrets(txt)}\n")
                continue
            except Exception as e:
                convert_logs.append(f"ğŸ“„ {name}: ë¡œì»¬ HWP/HWPX ì¶”ì¶œ ì‹¤íŒ¨ ({e}) â†’ ë‹¤ìŒ ë‹¨ê³„")

        if ext in TEXT_EXTS:
            for enc in ("utf-8-sig", "utf-8", "cp949", "euc-kr"):
                try:
                    txt = data.decode(enc)
                    break
                except Exception:
                    continue
            else:
                txt = data.decode("utf-8", errors="ignore")

            convert_logs.append(f"ğŸ—’ï¸ {name}: ë¡œì»¬ í…ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ")
            combined_texts.append(f"\n\n===== [{name}] =====\n{_redact_secrets(txt)}\n")
            continue

        if ext in DIRECT_PDF_EXTS:
            txt = extract_text_from_pdf_bytes(data)
            convert_logs.append(f"âœ… {name}: ë¡œì»¬ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ {len(txt)} chars")
            combined_texts.append(f"\n\n===== [{name}] =====\n{_redact_secrets(txt)}\n")
            continue

        if ext in BINARY_EXTS:
            pdf_bytes, dbg = cloudconvert_convert_to_pdf(data, name)
            if pdf_bytes:
                generated_pdfs.append((os.path.splitext(name)[0] + ".pdf", pdf_bytes))
                txt = extract_text_from_pdf_bytes(pdf_bytes)
                convert_logs.append(f"âœ… {name} â†’ CloudConvert PDF ì„±ê³µ ({dbg}), í…ìŠ¤íŠ¸ {len(txt)} chars")
                combined_texts.append(f"\n\n===== [{name} â†’ CloudConvert PDF] =====\n{_redact_secrets(txt)}\n")
            else:
                convert_logs.append(f"ğŸ›‘ {name}: CloudConvert ì‹¤íŒ¨ ({dbg})")
            continue

        convert_logs.append(f"â„¹ï¸ {name}: ë¯¸ì§€ì› í˜•ì‹(íŒ¨ìŠ¤)")

    return "\n".join(combined_texts).strip(), convert_logs, generated_pdfs


# =============================
# ë©”ë‰´
# =============================
menu_val = st.session_state.get("menu")

if menu_val == "ì¡°ë‹¬ì…ì°°ê²°ê³¼í˜„í™©":
    st.title("ğŸ“‘ ì¡°ë‹¬ì…ì°°ê²°ê³¼í˜„í™©")
    dl_buf = BytesIO()
    df_filtered.to_excel(dl_buf, index=False, engine="openpyxl")
    dl_buf.seek(0)
    st.download_button(
        label="ğŸ“¥ í•„í„°ë§ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (Excel)",
        data=dl_buf,
        file_name=f"filtered_result_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    st.data_editor(df_filtered, use_container_width=True, key="result_editor", height=520)
    with st.expander("ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„(ì°¨íŠ¸) ì—´ê¸°", expanded=False):
        render_basic_analysis_charts(df_filtered)

elif menu_val == "ë‚´ê³ ê° ë¶„ì„í•˜ê¸°":
    st.title("ğŸ§‘â€ğŸ’¼ ë‚´ê³ ê° ë¶„ì„í•˜ê¸°")
    st.info("â„¹ï¸ ì´ ë©”ë‰´ëŠ” ì‚¬ì´ë“œë°” í•„í„°ì™€ ë¬´ê´€í•˜ê²Œ **ì „ì²´ ì›ë³¸ ë°ì´í„°**ë¥¼ ëŒ€ìƒìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

    demand_col = None
    for col in ["ìˆ˜ìš”ê¸°ê´€ëª…", "ìˆ˜ìš”ê¸°ê´€", "ê¸°ê´€ëª…"]:
        if col in df_original.columns:
            demand_col = col
            break
    if not demand_col:
        st.error("âš ï¸ ìˆ˜ìš”ê¸°ê´€ ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    st.success(f"âœ… ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼: **{demand_col}**")

    customer_input = st.text_input(f"ê³ ê°ì‚¬ëª…ì„ ì…ë ¥í•˜ì„¸ìš” ({demand_col} ê¸°ì¤€, ì‰¼í‘œë¡œ ë³µìˆ˜ ì…ë ¥ ê°€ëŠ¥)", help="ì˜ˆ) ì¡°ë‹¬ì²­, êµ­ë°©ë¶€")

    with st.expander(f"ğŸ“‹ ì „ì²´ {demand_col} ëª©ë¡ ë³´ê¸° (ê²€ìƒ‰ ì°¸ê³ ìš©)"):
        unique_orgs = sorted(df_original[demand_col].dropna().unique())
        st.write(f"ì´ {len(unique_orgs)}ê°œ ê¸°ê´€")
        search_org = st.text_input("ê¸°ê´€ëª… ê²€ìƒ‰", key="search_org_in_my")
        view_orgs = [o for o in unique_orgs if (search_org in str(o))] if search_org else unique_orgs
        st.write(view_orgs[:120])

    if customer_input:
        customers = [c.strip() for c in customer_input.split(",") if c.strip()]
        if customers:
            result = df_original[df_original[demand_col].isin(customers)]
            st.subheader(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(result)}ê±´")
            if not result.empty:
                rb = BytesIO()
                result.to_excel(rb, index=False, engine="openpyxl")
                rb.seek(0)
                st.download_button(
                    label="ğŸ“¥ ê²°ê³¼ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (Excel)",
                    data=rb,
                    file_name=f"{'_'.join(customers)}_ì´ë ¥_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
                st.data_editor(result, use_container_width=True, key="customer_editor", height=520)

                # ===== ì²¨ë¶€ ë§í¬ ë§¤íŠ¸ë¦­ìŠ¤ =====
                st.markdown("---")
                st.subheader("ğŸ”— ì…ì°°ê³µê³ ëª… ê¸°ì¤€ìœ¼ë¡œ URLì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
                st.caption("(ë³¸ê³µê³ ë§í¬/ì œì•ˆìš”ì²­ì„œ/ê³µê³ ì„œ/ê³¼ì—…ì§€ì‹œì„œ/ê·œê²©ì„œ/ê¸°íƒ€, URL ì¤‘ë³µ ì œê±°)")
                title_col = next((c for c in ["ì…ì°°ê³µê³ ëª…", "ê³µê³ ëª…"] if c in result.columns), None)
                if title_col:
                    attach_df = build_attachment_matrix(result, title_col)
                    if not attach_df.empty:
                        use_compact = st.toggle("ğŸ”€ ê·¸ë£¹í˜•(Compact) ë³´ê¸°", value=True)
                        if use_compact:
                            st.markdown(render_attachment_cards_html(attach_df, title_col), unsafe_allow_html=True)
                        else:
                            st.dataframe(
                                attach_df.applymap(
                                    lambda x: '' if pd.isna(x) else re.sub(r"<[^>]+>", "", str(x))
                                )
                            )

                # ===== Gemini ë¶„ì„ =====
                st.markdown("---")
                st.subheader("ğŸ¤– Gemini ë¶„ì„")
                # [ì‚­ì œë¨] ìº¡ì…˜ ì‚­ì œ ìš”ì²­ ë°˜ì˜ë¨

                src_files = st.file_uploader(
                    "ë¶„ì„í•  íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
                    type=["pdf", "hwp", "hwpx", "doc", "docx", "ppt", "pptx", "xls", "xlsx", "txt", "csv", "md", "log"],
                    accept_multiple_files=True,
                    key="src_files_uploader",
                )

                if st.button("ğŸ§  Gemini ë¶„ì„ ë³´ê³ ì„œ ìƒì„±", type="primary", use_container_width=True):
                    if not src_files:
                        st.warning("ë¨¼ì € ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                    else:
                        with st.spinner("Geminiê°€ ì—…ë¡œë“œëœ ìë£Œë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘..."):
                            combined_text, logs, generated_pdfs = extract_text_combo_gemini_first(src_files)

                            st.session_state["gpt_convert_logs"] = logs

                            if not combined_text.strip():
                                st.error("ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                            else:
                                prompt = f"""
ë‹¤ìŒì€ ì¡°ë‹¬/ì…ì°° ê´€ë ¨ ë¬¸ì„œë“¤ì˜ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
í•µì‹¬ ìš”êµ¬ì‚¬í•­, ê¸°ìˆ /ê°€ê²© í‰ê°€ ë¹„ìœ¨, ê³„ì•½ì¡°ê±´, ì›”ê³¼ ì¼ì„ í¬í•¨í•œ ì •í™•í•œ ì¼ì •(ì…ì°° ë§ˆê°/ê³„ì•½ê¸°ê°„),
ê³µë™ìˆ˜ê¸‰/í•˜ë„ê¸‰/ê¸´ê¸‰ê³µê³  ì—¬ë¶€, ì£¼ìš” ì¥ë¹„/ìŠ¤í™/êµ¬ê°„,
ë°°ì •ì˜ˆì‚°/ì¶”ì •ê°€ê²©/ì˜ˆê°€ ë“±ì„ í‘œì™€ ë¶ˆë¦¿ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

[ë¬¸ì„œ í†µí•© í…ìŠ¤íŠ¸]
{combined_text[:180000]}
""".strip()
                                try:
                                    # âœ… ë°˜í™˜ê°’ 2ê°œ ë°›ê¸°
                                    report, used_model = call_gemini(
                                        [
                                            {"role": "system", "content": "ë‹¹ì‹ ì€ SKë¸Œë¡œë“œë°´ë“œ ë§ì„¤ê³„/ì¡°ë‹¬ ì œì•ˆ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                                            {"role": "user", "content": prompt},
                                        ],
                                        model="gemini-2.0-flash",
                                        max_tokens=2000,
                                        temperature=0.4,
                                    )

                                    st.session_state["gpt_report_md"] = report
                                    st.session_state["generated_src_pdfs"] = generated_pdfs

                                    # âœ… í™”ë©´ì— ì‚¬ìš©ëœ ëª¨ë¸ í‘œì‹œ
                                    st.success(f"ë³´ê³ ì„œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì‚¬ìš©ëœ ëª¨ë¸: **{used_model}**)")

                                except Exception as e:
                                    st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

                convert_logs_ss = st.session_state.get("gpt_convert_logs", [])
                if convert_logs_ss:
                    st.write("### ë³€í™˜/ì¶”ì¶œ ë¡œê·¸")
                    for line in convert_logs_ss:
                        st.write("- " + line)

                report_md = st.session_state.get("gpt_report_md")
                generated_pdfs = st.session_state.get("generated_src_pdfs", [])

                if report_md:
                    st.markdown("### ğŸ“ Gemini ë¶„ì„ ë³´ê³ ì„œ")
                    st.markdown(report_md)

                    base_fname = f"{'_'.join(customers)}_Geminië¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}"

                    st.download_button(
                        "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (.md)",
                        data=report_md.encode("utf-8"),
                        file_name=f"{base_fname}.md",
                        mime="text/markdown",
                        use_container_width=True
                    )

                    pdf_bytes, dbg = markdown_to_pdf_korean(report_md, title="Gemini ë¶„ì„ ë³´ê³ ì„œ")
                    if pdf_bytes:
                        st.download_button(
                            "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (.pdf)",
                            data=pdf_bytes,
                            file_name=f"{base_fname}.pdf",
                            mime="application/pdf",
                            use_container_width=True
                        )
                        st.caption(f"PDF ìƒì„± ìƒíƒœ: {dbg}")

                    if generated_pdfs:
                        st.markdown("---")
                        st.markdown("### ğŸ—‚ï¸ CloudConvertë¡œ ë³€í™˜ëœ PDF ë‚´ë ¤ë°›ê¸°")
                        for i, (fname, pbytes) in enumerate(generated_pdfs):
                            st.download_button(
                                label=f"ğŸ“¥ {fname}",
                                data=pbytes,
                                file_name=fname,
                                mime="application/pdf",
                                key=f"dl_ccpdf_{i}",
                                use_container_width=True,
                            )

                # ===== ì»¨í…ìŠ¤íŠ¸ ì±—ë´‡ =====
                st.markdown("---")
                st.subheader("ğŸ’¬ ë³´ê³ ì„œ/í…Œì´ë¸” ì°¸ì¡° ì±—ë´‡")
                question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
                if question:
                    st.session_state.setdefault("chat_messages", [])
                    st.session_state["chat_messages"].append({"role": "user", "content": question})

                    ctx_df = result.head(200).copy()
                    df_sample_csv = ctx_df.to_csv(index=False)[:20000]
                    report_ctx = st.session_state.get("gpt_report_md") or "(ì•„ì§ ë³´ê³ ì„œ ì—†ìŒ)"

                    q_prompt = f"""
[ìš”ì•½ ë³´ê³ ì„œ]
{report_ctx}

[í‘œ ë°ì´í„° ì¼ë¶€ CSV]
{df_sample_csv}

ì§ˆë¬¸: {question}
ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•´ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µí•˜ì„¸ìš”. í‘œ/ë¶ˆë¦¿ ì ê·¹ í™œìš©.
""".strip()

                    try:
                        # âœ… ë°˜í™˜ê°’ 2ê°œ ë°›ê¸°
                        ans, used_model = call_gemini(
                            [
                                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¡°ë‹¬/í†µì‹  ì œì•ˆ ë¶„ì„ ì±—ë´‡ì…ë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."},
                                {"role": "user", "content": q_prompt},
                            ],
                            model="gemini-2.0-flash",
                            max_tokens=1200,
                            temperature=0.2,
                        )
                        # âœ… ë‹µë³€ ëì— ëª¨ë¸ëª… ë¶™ì—¬ì£¼ê¸°
                        final_ans = f"{ans}\n\n_(Generated by **{used_model}**)_"
                        st.session_state["chat_messages"].append({"role": "assistant", "content": final_ans})
                    except Exception as e:
                        st.session_state["chat_messages"].append({"role": "assistant", "content": f"ì˜¤ë¥˜: {e}"})

                for m in st.session_state.get("chat_messages", []):
                    st.chat_message("user" if m["role"] == "user" else "assistant").markdown(m["content"])

# === EOF ===
